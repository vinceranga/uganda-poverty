{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-04T00:18:52.056478",
     "start_time": "2018-04-04T00:18:50.879887"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Reshape, Activation, Conv2D, Input, MaxPooling2D, BatchNormalization, Flatten, Dense, Lambda\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.layers.merge import concatenate\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "# import imgaug as ia\n",
    "# from tqdm import tqdm\n",
    "# from imgaug import augmenters as iaa\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os, cv2\n",
    "# from preprocessing import parse_annotation, BatchGenerator\n",
    "from utils import WeightReader, decode_netout #, draw_boxes\n",
    "import time\n",
    "\n",
    "from glob import glob\n",
    "import gc_util as gc\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-04T00:18:52.075535",
     "start_time": "2018-04-04T00:18:52.057712"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LABELS = ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n",
    "# LABELS = ['Fixed-wing Aircraft', 'Small Aircraft', 'Cargo Plane', 'Helicopter', 'Passenger Vehicle', 'Small Car', 'Bus', 'Pickup Truck', 'Utility Truck', 'Truck', 'Cargo Truck', 'Truck w/Box', 'Truck Tractor', 'Trailer', 'Truck w/Flatbed', 'Truck w/Liquid', 'Crane Truck', 'Railway Vehicle', 'Passenger Car', 'Cargo Car', 'Flat Car', 'Tank car', 'Locomotive', 'Maritime Vessel', 'Motorboat', 'Sailboat', 'Tugboat', 'Barge', 'Fishing Vessel', 'Ferry', 'Yacht', 'Container Ship', 'Oil Tanker', 'Engineering Vehicle', 'Tower crane', 'Container Crane', 'Reach Stacker', 'Straddle Carrier', 'Mobile Crane', 'Dump Truck', 'Haul Truck', 'Scraper/Tractor', 'Front loader/Bulldozer', 'Excavator', 'Cement Mixer', 'Ground Grader', 'Hut/Tent', 'Shed', 'Building', 'Aircraft Hangar', 'Damaged Building', 'Facility', 'Construction Site', 'Vehicle Lot', 'Helipad', 'Storage Tank', 'Shipping container lot', 'Shipping Container', 'Pylon', 'Tower']\n",
    "#LABELS = ['Small Car','Truck','Bus']\n",
    "LABELS=['Building']\n",
    "IMAGE_H, IMAGE_W = 416, 416\n",
    "GRID_H,  GRID_W  = 13, 13   # Vince: changed from 13 to 8\n",
    "BOX              = 5\n",
    "CLASS            = len(LABELS)\n",
    "CLASS_WEIGHTS    = np.ones(CLASS, dtype='float32')\n",
    "OBJ_THRESHOLD    = 0.5#0.5\n",
    "NMS_THRESHOLD    = 0.2#0.45\n",
    "#ANCHORS          = [0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828]\n",
    "ANCHORS          = [0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828]\n",
    "NO_OBJECT_SCALE  = 1.0\n",
    "OBJECT_SCALE     = 5.0\n",
    "COORD_SCALE      = 1.0\n",
    "CLASS_SCALE      = 1.0\n",
    "\n",
    "BATCH_SIZE       = 16\n",
    "WARM_UP_BATCHES  = 0\n",
    "TRUE_BOX_BUFFER  = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-04T00:18:53.978220",
     "start_time": "2018-04-04T00:18:53.967537"
    }
   },
   "outputs": [],
   "source": [
    "# the function to implement the orgnization layer (thanks to github.com/allanzelener/YAD2K)\n",
    "def space_to_depth_x2(x):\n",
    "    return tf.space_to_depth(x, block_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-04T00:18:58.022959",
     "start_time": "2018-04-04T00:18:55.740759"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "input_image = Input(shape=(IMAGE_H, IMAGE_W, 3))\n",
    "true_boxes  = Input(shape=(1, 1, 1, TRUE_BOX_BUFFER , 4))\n",
    "\n",
    "# Layer 1\n",
    "x = Conv2D(32, (3,3), strides=(1,1), padding='same', name='conv_1', use_bias=False)(input_image)\n",
    "x = BatchNormalization(name='norm_1')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 2\n",
    "x = Conv2D(64, (3,3), strides=(1,1), padding='same', name='conv_2', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_2')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 3\n",
    "x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_3', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_3')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 4\n",
    "x = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_4', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_4')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 5\n",
    "x = Conv2D(128, (3,3), strides=(1,1), padding='same', name='conv_5', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_5')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 6\n",
    "x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_6', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_6')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 7\n",
    "x = Conv2D(128, (1,1), strides=(1,1), padding='same', name='conv_7', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_7')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 8\n",
    "x = Conv2D(256, (3,3), strides=(1,1), padding='same', name='conv_8', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_8')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 9\n",
    "x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_9', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_9')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 10\n",
    "x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_10', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_10')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 11\n",
    "x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_11', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_11')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 12\n",
    "x = Conv2D(256, (1,1), strides=(1,1), padding='same', name='conv_12', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_12')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 13\n",
    "x = Conv2D(512, (3,3), strides=(1,1), padding='same', name='conv_13', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_13')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "skip_connection = x\n",
    "\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Layer 14\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_14', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_14')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 15\n",
    "x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_15', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_15')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 16\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_16', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_16')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 17\n",
    "x = Conv2D(512, (1,1), strides=(1,1), padding='same', name='conv_17', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_17')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 18\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_18', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_18')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 19\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_19', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_19')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 20\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_20', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_20')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 21\n",
    "skip_connection = Conv2D(64, (1,1), strides=(1,1), padding='same', name='conv_21', use_bias=False)(skip_connection)\n",
    "skip_connection = BatchNormalization(name='norm_21')(skip_connection)\n",
    "skip_connection = LeakyReLU(alpha=0.1)(skip_connection)\n",
    "skip_connection = Lambda(space_to_depth_x2)(skip_connection)\n",
    "\n",
    "x = concatenate([skip_connection, x])\n",
    "\n",
    "# Layer 22\n",
    "x = Conv2D(1024, (3,3), strides=(1,1), padding='same', name='conv_22', use_bias=False)(x)\n",
    "x = BatchNormalization(name='norm_22')(x)\n",
    "x = LeakyReLU(alpha=0.1)(x)\n",
    "\n",
    "# Layer 23\n",
    "x = Conv2D(BOX * (4 + 1 + CLASS), (1,1), strides=(1,1), padding='same', name='conv_23')(x)\n",
    "output = Reshape((GRID_H, GRID_W, BOX, 4 + 1 + CLASS))(x)\n",
    "\n",
    "# small hack to allow true_boxes to be registered when Keras build the model \n",
    "# for more information: https://github.com/fchollet/keras/issues/2790\n",
    "output = Lambda(lambda args: args[0])([output, true_boxes])\n",
    "\n",
    "model = Model([input_image, true_boxes], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-26T12:34:03.819802Z",
     "start_time": "2017-11-26T12:34:03.786125Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parse the annotations to construct train generator and validation generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-26T12:38:44.283547Z",
     "start_time": "2017-11-26T12:38:44.277155Z"
    }
   },
   "outputs": [],
   "source": [
    "generator_config = {\n",
    "    'IMAGE_H'         : IMAGE_H, \n",
    "    'IMAGE_W'         : IMAGE_W,\n",
    "    'GRID_H'          : GRID_H,  \n",
    "    'GRID_W'          : GRID_W,\n",
    "    'BOX'             : BOX,\n",
    "    'LABELS'          : LABELS,\n",
    "    'CLASS'           : len(LABELS),\n",
    "    'ANCHORS'         : ANCHORS,\n",
    "    'BATCH_SIZE'      : BATCH_SIZE,\n",
    "    'TRUE_BOX_BUFFER' : 50,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform detection on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-22T14:07:49.271978Z",
     "start_time": "2017-11-22T14:07:49.268999Z"
    }
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"weights_building.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ids = [10130002, 10210001, 10210002, 10210012, 10210013, 10210028, 10210031, 10210034, 10330003]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyper import IMG_ID as img_id\n",
    "from hyper import NUM_SQ\n",
    "from hyper import OBJ_THRESH as obj_thresh\n",
    "from hyper import WH\n",
    "COORDS = [(i, j) for i in range(0,1000,WH) for j in range(0,1000,WH)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(img_id):\n",
    "    sqs = [i for i in range(1, NUM_SQ+1)]\n",
    "    gc.open_images(img_id, sqs)\n",
    "\n",
    "    img_files = 'LSMS_dg/dg_lsms_uganda_1000x1000_' + str(img_id) + '_*.jpeg'\n",
    "    val_files = glob(img_files)\n",
    "\n",
    "    def fn(name):\n",
    "        return int(name[42:-5])  # parsing out the sq variable\n",
    "\n",
    "    val_files = sorted(val_files, key=fn)\n",
    "    val_files = val_files[:NUM_SQ]\n",
    "    print(\"Acquired files for %d\" %img_id)\n",
    "    \n",
    "    return val_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_detection(img_id, val_files, verbose=False):\n",
    "    # assumes that img_id matches the val_files\n",
    "    \n",
    "    base = \"boxes/%d\" %img_id\n",
    "    if not os.path.exists(base):\n",
    "        os.makedirs(base)\n",
    "    \n",
    "    print(\"Performing object detection at %d on %s tiles, each %s chips of w,h=%s\" % (img_id, NUM_SQ, int((1000/WH)**2), WH))\n",
    "    if verbose: print()\n",
    "    \n",
    "    start = time.time()\n",
    "    for k, img_path in enumerate(val_files):\n",
    "        \n",
    "        # check if file has already been scanned\n",
    "        tst_name = base + '/' + img_path[8:-5] + '_' + str(int((1000/WH)**2) - 1) + '.pickle'\n",
    "        if os.path.isfile(tst_name):\n",
    "            continue\n",
    "        \n",
    "        # measuring progress if so desired\n",
    "        if verbose:\n",
    "            if (k+1) % 100 == 0:\n",
    "                pdone = float(k) / len(val_files)\n",
    "                curr_time = time.time()\n",
    "                rem = int((1-pdone)/pdone * (curr_time - start))\n",
    "                print(\"%.2f percent done at sq %s. ETC: %s:%02d\" % (100 * pdone, k+1, int(rem / 60), rem % 60))\n",
    "\n",
    "        image = cv2.imread(img_path)\n",
    "\n",
    "        # if unable to load image, redownload and try again\n",
    "        if image is None:\n",
    "            if os.path.exists(img_path):\n",
    "                os.remove(img_path)\n",
    "            gs.open_images(img_id, k+1)\n",
    "            image = cv2.imread(img_path)\n",
    "            if image is None:\n",
    "                print(\"Error processing %s, continuing with rest of objects\" %img_path)\n",
    "                continue\n",
    "        \n",
    "        for idx, coord_pair in enumerate(COORDS):\n",
    "            image_quarter = image[coord_pair[0]:coord_pair[0]+WH,\n",
    "                                  coord_pair[1]:coord_pair[1]+WH]\n",
    "\n",
    "            dummy_array = np.zeros((1,1,1,1,TRUE_BOX_BUFFER,4))\n",
    "            input_image = cv2.resize(image_quarter, (416, 416))\n",
    "            input_image = input_image / 255.\n",
    "            input_image = input_image[:,:,::-1]  # reversing RGB channels\n",
    "            input_image = np.expand_dims(input_image, 0)\n",
    "            netout = model.predict([input_image, dummy_array])\n",
    "\n",
    "            boxes = decode_netout(netout[0],\n",
    "                              obj_threshold=obj_thresh,\n",
    "                              nms_threshold=NMS_THRESHOLD,\n",
    "                              anchors=ANCHORS,\n",
    "                              nb_class=CLASS)\n",
    "\n",
    "            for box in boxes:\n",
    "                image_h, image_w, _ = image_quarter.shape\n",
    "\n",
    "                box.xmin *= image_w\n",
    "                box.ymin *= image_h\n",
    "                box.xmax *= image_w\n",
    "                box.ymax *= image_h\n",
    "\n",
    "            # now separating into individual folders for cleanliness\n",
    "            out_name = base + '/' + img_path[8:-5] + '_' + str(idx) + '.pickle'\n",
    "            pickle_out = open(out_name, \"wb\")\n",
    "            pickle.dump(boxes, pickle_out)\n",
    "            pickle_out.close()\n",
    "            \n",
    "    if verbose: print()\n",
    "    print(\"Object detection completed!\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acquired files for 10130002\n",
      "Performing object detection at 10130002 on 1156 tiles, each 4 chips of w,h=500\n",
      "\n",
      "Error processing LSMS_dg/dg_lsms_uganda_1000x1000_10130002_662.jpeg, continuing with rest of objects\n",
      "60.47 percent done at sq 700. ETC: 0:48\n",
      "69.12 percent done at sq 800. ETC: 2:13\n",
      "77.77 percent done at sq 900. ETC: 2:28\n",
      "86.42 percent done at sq 1000. ETC: 1:56\n",
      "\n",
      "Object detection completed!\n",
      "\n",
      "Acquired files for 10210001\n",
      "Performing object detection at 10210001 on 1156 tiles, each 4 chips of w,h=500\n",
      "\n",
      "8.56 percent done at sq 100. ETC: 39:56\n",
      "17.21 percent done at sq 200. ETC: 36:16\n",
      "25.87 percent done at sq 300. ETC: 32:30\n",
      "34.52 percent done at sq 400. ETC: 28:43\n",
      "43.17 percent done at sq 500. ETC: 24:54\n",
      "51.82 percent done at sq 600. ETC: 21:04\n",
      "60.47 percent done at sq 700. ETC: 17:16\n",
      "69.12 percent done at sq 800. ETC: 13:28\n",
      "77.77 percent done at sq 900. ETC: 9:41\n",
      "86.42 percent done at sq 1000. ETC: 5:54\n",
      "95.07 percent done at sq 1100. ETC: 2:08\n",
      "\n",
      "Object detection completed!\n",
      "\n",
      "Acquired files for 10210002\n",
      "Performing object detection at 10210002 on 1156 tiles, each 4 chips of w,h=500\n",
      "\n",
      "8.56 percent done at sq 100. ETC: 39:41\n",
      "17.21 percent done at sq 200. ETC: 35:47\n",
      "25.87 percent done at sq 300. ETC: 31:59\n",
      "34.52 percent done at sq 400. ETC: 28:16\n",
      "43.17 percent done at sq 500. ETC: 24:30\n",
      "51.82 percent done at sq 600. ETC: 20:45\n",
      "60.47 percent done at sq 700. ETC: 17:01\n",
      "69.12 percent done at sq 800. ETC: 13:17\n",
      "77.77 percent done at sq 900. ETC: 9:33\n",
      "86.42 percent done at sq 1000. ETC: 5:50\n",
      "\n",
      "Object detection completed!\n",
      "\n",
      "Acquired files for 10210012\n",
      "Performing object detection at 10210012 on 1156 tiles, each 4 chips of w,h=500\n",
      "\n",
      "8.56 percent done at sq 100. ETC: 39:37\n",
      "17.21 percent done at sq 200. ETC: 35:44\n",
      "25.87 percent done at sq 300. ETC: 32:01\n",
      "34.52 percent done at sq 400. ETC: 28:16\n",
      "43.17 percent done at sq 500. ETC: 24:31\n",
      "51.82 percent done at sq 600. ETC: 20:47\n",
      "60.47 percent done at sq 700. ETC: 17:04\n",
      "69.12 percent done at sq 800. ETC: 13:19\n",
      "77.77 percent done at sq 900. ETC: 9:34\n",
      "86.42 percent done at sq 1000. ETC: 5:51\n",
      "95.07 percent done at sq 1100. ETC: 2:07\n",
      "\n",
      "Object detection completed!\n",
      "\n",
      "Acquired files for 10210013\n",
      "Performing object detection at 10210013 on 1156 tiles, each 4 chips of w,h=500\n",
      "\n",
      "8.56 percent done at sq 100. ETC: 39:17\n",
      "17.21 percent done at sq 200. ETC: 35:41\n",
      "25.87 percent done at sq 300. ETC: 31:58\n",
      "34.52 percent done at sq 400. ETC: 28:16\n",
      "43.17 percent done at sq 500. ETC: 24:31\n",
      "51.82 percent done at sq 600. ETC: 20:47\n",
      "60.47 percent done at sq 700. ETC: 17:03\n",
      "69.12 percent done at sq 800. ETC: 13:19\n",
      "77.77 percent done at sq 900. ETC: 9:34\n",
      "86.42 percent done at sq 1000. ETC: 5:51\n",
      "95.07 percent done at sq 1100. ETC: 2:07\n",
      "\n",
      "Object detection completed!\n",
      "\n",
      "Acquired files for 10210028\n",
      "Performing object detection at 10210028 on 1156 tiles, each 4 chips of w,h=500\n",
      "\n",
      "8.56 percent done at sq 100. ETC: 39:30\n",
      "17.21 percent done at sq 200. ETC: 35:54\n",
      "25.87 percent done at sq 300. ETC: 32:04\n",
      "34.52 percent done at sq 400. ETC: 28:23\n",
      "43.17 percent done at sq 500. ETC: 24:39\n",
      "51.82 percent done at sq 600. ETC: 20:54\n",
      "60.47 percent done at sq 700. ETC: 17:07\n",
      "69.12 percent done at sq 800. ETC: 13:22\n",
      "77.77 percent done at sq 900. ETC: 9:36\n",
      "86.42 percent done at sq 1000. ETC: 5:51\n",
      "95.07 percent done at sq 1100. ETC: 2:07\n",
      "\n",
      "Object detection completed!\n",
      "\n",
      "Acquired files for 10210031\n",
      "Performing object detection at 10210031 on 1156 tiles, each 4 chips of w,h=500\n",
      "\n",
      "8.56 percent done at sq 100. ETC: 39:33\n",
      "17.21 percent done at sq 200. ETC: 35:44\n",
      "25.87 percent done at sq 300. ETC: 32:04\n",
      "34.52 percent done at sq 400. ETC: 28:22\n",
      "43.17 percent done at sq 500. ETC: 24:37\n",
      "60.47 percent done at sq 700. ETC: 17:09\n",
      "69.12 percent done at sq 800. ETC: 13:24\n",
      "77.77 percent done at sq 900. ETC: 9:39\n",
      "86.42 percent done at sq 1000. ETC: 5:54\n",
      "95.07 percent done at sq 1100. ETC: 2:08\n",
      "\n",
      "Object detection completed!\n",
      "\n",
      "Acquired files for 10210034\n",
      "Performing object detection at 10210034 on 1156 tiles, each 4 chips of w,h=500\n",
      "\n",
      "8.56 percent done at sq 100. ETC: 39:34\n",
      "17.21 percent done at sq 200. ETC: 35:50\n",
      "25.87 percent done at sq 300. ETC: 32:08\n",
      "34.52 percent done at sq 400. ETC: 28:25\n",
      "43.17 percent done at sq 500. ETC: 24:40\n",
      "51.82 percent done at sq 600. ETC: 20:56\n",
      "60.47 percent done at sq 700. ETC: 17:11\n",
      "69.12 percent done at sq 800. ETC: 13:25\n",
      "77.77 percent done at sq 900. ETC: 9:39\n",
      "86.42 percent done at sq 1000. ETC: 5:54\n",
      "95.07 percent done at sq 1100. ETC: 2:08\n",
      "\n",
      "Object detection completed!\n",
      "\n",
      "Acquired files for 10330003\n",
      "Performing object detection at 10330003 on 1156 tiles, each 4 chips of w,h=500\n",
      "\n",
      "8.56 percent done at sq 100. ETC: 39:13\n",
      "17.21 percent done at sq 200. ETC: 35:32\n",
      "25.87 percent done at sq 300. ETC: 31:47\n",
      "34.52 percent done at sq 400. ETC: 28:05\n",
      "43.17 percent done at sq 500. ETC: 24:23\n",
      "51.82 percent done at sq 600. ETC: 20:40\n",
      "60.47 percent done at sq 700. ETC: 16:57\n",
      "69.12 percent done at sq 800. ETC: 13:15\n",
      "77.77 percent done at sq 900. ETC: 9:32\n",
      "86.42 percent done at sq 1000. ETC: 5:49\n",
      "95.07 percent done at sq 1100. ETC: 2:06\n",
      "\n",
      "Object detection completed!\n",
      "\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-4b35109f97cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mval_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mobject_detection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-54ca68ff7d20>\u001b[0m in \u001b[0;36mget_files\u001b[0;34m(img_id)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNUM_SQ\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mimg_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'LSMS_dg/dg_lsms_uganda_1000x1000_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_*.jpeg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/poverty/gc_util.py\u001b[0m in \u001b[0;36mopen_images\u001b[0;34m(img_id, sqs)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mblob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbucket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mblob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload_to_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# print(\"Image downloaded!\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/google/cloud/storage/blob.py\u001b[0m in \u001b[0;36mdownload_to_filename\u001b[0;34m(self, filename, client, start, end)\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile_obj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m                 self.download_to_file(\n\u001b[0;32m--> 565\u001b[0;31m                     file_obj, client=client, start=start, end=end)\n\u001b[0m\u001b[1;32m    566\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mresumable_media\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataCorruption\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m             \u001b[0;31m# Delete the corrupt downloaded file.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/google/cloud/storage/blob.py\u001b[0m in \u001b[0;36mdownload_to_file\u001b[0;34m(self, file_obj, client, start, end)\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             self._do_download(\n\u001b[0;32m--> 535\u001b[0;31m                 transport, file_obj, download_url, headers, start, end)\n\u001b[0m\u001b[1;32m    536\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mresumable_media\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidResponse\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m             \u001b[0m_raise_from_invalid_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/google/cloud/storage/blob.py\u001b[0m in \u001b[0;36m_do_download\u001b[0;34m(self, transport, file_obj, download_url, headers, start, end)\u001b[0m\n\u001b[1;32m    475\u001b[0m                 \u001b[0mdownload_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfile_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m                 start=start, end=end)\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mdownload\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             download = ChunkedDownload(\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/google/resumable_media/requests/download.py\u001b[0m in \u001b[0;36mconsume\u001b[0;34m(self, transport)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write_to_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/google/resumable_media/requests/download.py\u001b[0m in \u001b[0;36m_write_to_stream\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    122\u001b[0m                 chunk_size=_SINGLE_GET_CHUNK_SIZE, decode_unicode=False)\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbody_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m                 \u001b[0mlocal_hash\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "for img_id in val_ids:\n",
    "    val_files = get_files(img_id)\n",
    "    object_detection(img_id, val_files, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyper import HOUSE_SIZE_THRESH\n",
    "from hyper import HOUSE_LEN_THRESH\n",
    "\n",
    "def draw_boxes_coords(img_id, sq, coords=COORDS, filter_size=True, filter_green=True):\n",
    "    img_path = \"LSMS_dg/dg_lsms_uganda_1000x1000_\" + str(img_id) + \"_\" + str(sq) + \".jpeg\"\n",
    "    \n",
    "    imgs = []\n",
    "    \n",
    "    if sq % 50 == 1:\n",
    "        print(\"Currently at sq %d\" %sq)\n",
    "    \n",
    "    for idx, coord_pair in enumerate(coords):\n",
    "        pickle_path = \"boxes/\" + str(img_id) + \"/dg_lsms_uganda_1000x1000_\" + str(img_id) + \"_\" + str(sq) + \"_\" + str(idx) + \".pickle\"\n",
    "\n",
    "        pickle_in = open(pickle_path, \"rb\")\n",
    "        boxes = pickle.load(pickle_in)\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "        img = img[coord_pair[0]:coord_pair[0]+WH,\n",
    "                  coord_pair[1]:coord_pair[1]+WH]\n",
    "\n",
    "        for tbox in boxes:\n",
    "            if filter_size:\n",
    "                size = (tbox.xmax - tbox.xmin) * (tbox.ymax - tbox.ymin)\n",
    "                def bad_house_size(tbox):\n",
    "                    return size > HOUSE_SIZE_THRESH or (tbox.xmax - tbox.xmin) > HOUSE_LEN_THRESH or (tbox.ymax - tbox.ymin) > HOUSE_LEN_THRESH\n",
    "                if bad_house_size(tbox): continue\n",
    "            \n",
    "            p1 = (int(tbox.xmin), int(tbox.ymin))\n",
    "            p2 = (int(tbox.xmax), int(tbox.ymax))\n",
    "            \n",
    "            if filter_green:\n",
    "                reg = np.array(img[p1[1]:p2[1], p1[0]:p2[0]])\n",
    "                # plt.imshow(reg)\n",
    "                # plt.show()\n",
    "                \n",
    "                def bad_green_maj(reg, thresh=0.70):\n",
    "                    num_pix = (p2[1] - p1[1]) * (p2[0] - p1[0])\n",
    "                    green = reg[:,:,1]\n",
    "                    mxd = np.amax(reg, axis=2)\n",
    "                    num_nongreen = np.count_nonzero(green - mxd)\n",
    "                    pc = 1 - float(num_nongreen) / num_pix\n",
    "                    # print(pc)\n",
    "                    return pc > thresh\n",
    "                \n",
    "                if bad_green_maj(reg): continue\n",
    "                \n",
    "            img = cv2.rectangle(img, p1, p2, (255,0,0), thickness=1)\n",
    "    \n",
    "        imgs.append(img)\n",
    "    \n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_boxes_coords(img_id, sq, coords=COORDS, filter_size=True, filter_green=True):\n",
    "    imgs = draw_boxes_coords(img_id, sq, coords=COORDS, filter_size=filter_size, filter_green=filter_green)\n",
    "    \n",
    "    if WH == 250:\n",
    "        rws = []\n",
    "        for k in range(0,16,4):\n",
    "            rws.append(np.concatenate([imgs[k], imgs[k+1], imgs[k+2], imgs[k+3]], axis=1))\n",
    "        img = np.concatenate([rws[0], rws[1], rws[2], rws[3]], axis=0)\n",
    "        path = \"box_imgs/dg_lsms_uganda_1000x1000_%s_%s_boxed.jpeg\" % (img_id, sq)\n",
    "        cv2.imwrite(path, img)\n",
    "    elif WH == 500:\n",
    "        for idx in range(len(coords)):\n",
    "            path = \"box_imgs/dg_lsms_uganda_1000x1000_\" + str(img_id) + \"_\" + str(sq) + \"_\" + str(idx) + \".jpeg\"\n",
    "            cv2.imwrite(path, imgs[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently at sq 1\n",
      "Currently at sq 51\n",
      "Currently at sq 101\n",
      "Currently at sq 151\n",
      "Currently at sq 201\n",
      "Currently at sq 251\n",
      "Currently at sq 301\n",
      "Currently at sq 351\n",
      "Currently at sq 401\n",
      "Currently at sq 451\n",
      "Currently at sq 501\n",
      "Currently at sq 551\n",
      "Currently at sq 601\n",
      "Currently at sq 651\n",
      "Currently at sq 701\n",
      "Currently at sq 751\n",
      "Currently at sq 801\n",
      "Currently at sq 851\n",
      "Currently at sq 901\n",
      "Currently at sq 951\n",
      "Currently at sq 1001\n",
      "Currently at sq 1051\n",
      "Currently at sq 1101\n",
      "Currently at sq 1151\n"
     ]
    }
   ],
   "source": [
    "for sq in range(1, NUM_SQ+1):\n",
    "    save_boxes_coords(img_id, sq, filter_size=True, filter_green=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete folders for restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full',)).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "def empty_folder(folder):\n",
    "    import shutil\n",
    "    if os.path.exists(folder):\n",
    "        shutil.rmtree(folder)\n",
    "        os.makedirs(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "empty_folder(\"LSMS_dg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_folder(\"box_imgs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "empty_folder(\"boxes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "toc": {
   "nav_menu": {
    "height": "122px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "758px",
    "left": "0px",
    "right": "1096px",
    "top": "73px",
    "width": "253px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
